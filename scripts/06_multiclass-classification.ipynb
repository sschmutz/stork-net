{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiclass classification of stork nest images\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/sschmutz/stork-net/blob/master/scripts/06_multiclass-classification.ipynb)  \n",
    "To use Google Colab, click on the link above and then change the Runtime type to Python 3 under \"Runtime\" - \"Change runtime type\". And for faster computation select GPU under \"Hardware accelerator\".\n",
    "\n",
    "Code is adapted from the [TensorFlow Tutorial on Image classification](https://www.tensorflow.org/tutorials/images/classification).\n",
    "\n",
    "The goal is to classify images of a stork nest in four categories, how many storks are present (0-3). The images were collected from a publicly available [webcam](https://www.berner-storch.ch/webcam/) and manually labeled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import os\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load images\n",
    "Labeled images are already split and [available on GitHub](https://github.com/sschmutz/stork-net-dataset).\n",
    "The full dataset will be downloaded with the following comand, this enables us to use this notebook in google colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = tf.keras.utils.get_file(origin=\"https://github.com/sschmutz/stork-net-dataset/archive/master.zip\", fname=\"stork-net-dataset-master.zip\", extract=True)\n",
    "data_dir = pathlib.Path(os.path.splitext(data_dir)[0])\n",
    "\n",
    "train_dir = pathlib.Path(data_dir, \"2019_train\", \"train\")\n",
    "validation_dir = pathlib.Path(data_dir, \"2019_train\", \"validation\")\n",
    "test_dir = pathlib.Path(data_dir, \"2019_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_0_stork_train = len(list(train_dir.glob(\"0_stork/*.jpg\")))\n",
    "num_1_stork_train = len(list(train_dir.glob(\"1_stork/*.jpg\")))\n",
    "num_2_stork_train = len(list(train_dir.glob(\"2_stork/*.jpg\")))\n",
    "num_3_stork_train = len(list(train_dir.glob(\"3_stork/*.jpg\")))\n",
    "\n",
    "num_0_stork_val = len(list(validation_dir.glob(\"0_stork/*.jpg\")))\n",
    "num_1_stork_val = len(list(validation_dir.glob(\"1_stork/*.jpg\")))\n",
    "num_2_stork_val = len(list(validation_dir.glob(\"2_stork/*.jpg\")))\n",
    "num_3_stork_val = len(list(validation_dir.glob(\"3_stork/*.jpg\")))\n",
    "\n",
    "num_0_stork_test = len(list(test_dir.glob(\"0_stork/*.jpg\")))\n",
    "num_1_stork_test = len(list(test_dir.glob(\"1_stork/*.jpg\")))\n",
    "num_2_stork_test = len(list(test_dir.glob(\"2_stork/*.jpg\")))\n",
    "num_3_stork_test = len(list(test_dir.glob(\"3_stork/*.jpg\")))\n",
    "\n",
    "total_train = len(list(train_dir.glob(\"*/*.jpg\")))\n",
    "total_val = len(list(validation_dir.glob(\"*/*.jpg\")))\n",
    "total_test = len(list(test_dir.glob(\"*/*.jpg\")))\n",
    "\n",
    "class_names = np.array([item.name for item in train_dir.glob(\"*\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I'm not sure if the numbers have to be divisible by the batch size.\n",
    "batch_size = 64 \n",
    "epochs = 15\n",
    "img_height = 480\n",
    "img_width = 640\n",
    "channels = 3 #set to 1 if greyscale is used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data augmentation can be defined already inside ***ImageDataGenerator()***, see the respective section on the [keras website](https://keras.io/api/preprocessing/image/).  \n",
    "I've tried data augmentation (if applied, only do it on the training data) as described in [this tutorial](https://www.tensorflow.org/tutorials/images/classification). It didn't improve the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The 1./255 is to convert from uint8 to float32 in range [0,1]\n",
    "train_image_generator = ImageDataGenerator(rescale=1./255)\n",
    "validation_image_generator = ImageDataGenerator(rescale=1./255)\n",
    "test_image_generator = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Should we change the color-images to grayscale? This way one can maybe use images from the infrared camera at night.\n",
    "This could be done in ***flow_from_directory()***, just define following parameter: ***color_mode=\"grayscale\"*** (default is \"rgb\").  \n",
    "I've tried doing this. Didn't really improve the model.\n",
    "\n",
    "If we use a multiclass-classification problem, we can define ***class_mode=\"categorical\"***. Labels will be automatically be 2D one-hot encoded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_gen = train_image_generator.flow_from_directory(batch_size=batch_size,\n",
    "                                                           directory=train_dir,\n",
    "                                                           shuffle=True,\n",
    "                                                           target_size=(img_height, img_width),\n",
    "                                                           class_mode=\"categorical\",\n",
    "                                                           classes = list(class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data_gen = validation_image_generator.flow_from_directory(batch_size=batch_size,\n",
    "                                                              directory=validation_dir,\n",
    "                                                              shuffle=True,\n",
    "                                                              target_size=(img_height, img_width),\n",
    "                                                              class_mode=\"categorical\",\n",
    "                                                              classes = list(class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_gen = test_image_generator.flow_from_directory(batch_size=batch_size,\n",
    "                                                         directory=test_dir,\n",
    "                                                         shuffle=True,\n",
    "                                                         target_size=(img_height, img_width),\n",
    "                                                         class_mode=\"categorical\",\n",
    "                                                         classes = list(class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_training_images, sample_training_labels = next(train_data_gen)\n",
    "sample_validation_images, sample_validation_labels = next(val_data_gen)\n",
    "sample_test_images, sample_test_labels = next(test_data_gen)\n",
    "\n",
    "# decode one-hot encoded labels\n",
    "sample_training_labels = tf.argmax(sample_training_labels, axis=1)\n",
    "sample_validation_labels = tf.argmax(sample_validation_labels, axis=1)\n",
    "sample_test_labels = tf.argmax(sample_test_labels, axis=1)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "for i in range(25):\n",
    "    plt.subplot(5,5,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(sample_training_images[i], cmap=plt.cm.binary)\n",
    "    plt.xlabel(class_names[sample_training_labels[i]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# added dropout of 10% to first and last max pool layer\n",
    "\n",
    "model = Sequential([\n",
    "    Conv2D(16, 3, padding=\"same\", activation=\"relu\", input_shape=(img_height, img_width, channels)),\n",
    "    MaxPooling2D(),\n",
    "    Dropout(0.1),\n",
    "    Conv2D(32, 3, padding=\"same\", activation=\"relu\"),\n",
    "    MaxPooling2D(),\n",
    "    Conv2D(64, 3, padding=\"same\", activation=\"relu\"),\n",
    "    MaxPooling2D(),\n",
    "    Dropout(0.1),\n",
    "    Flatten(),\n",
    "    Dense(64, activation=\"relu\"),\n",
    "    Dense(4, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\",\n",
    "              loss=\"categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_data_gen,\n",
    "    steps_per_epoch=total_train // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=val_data_gen,\n",
    "    validation_steps=total_val // batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "model.save(\"stork_net_v2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history[\"accuracy\"]\n",
    "val_acc = history.history[\"val_accuracy\"]\n",
    "\n",
    "loss=history.history[\"loss\"]\n",
    "val_loss=history.history[\"val_loss\"]\n",
    "\n",
    "epochs_range = range(epochs)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label=\"Training Accuracy\")\n",
    "plt.plot(epochs_range, val_acc, label=\"Validation Accuracy\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.title(\"Training and Validation Accuracy\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label=\"Training Loss\")\n",
    "plt.plot(epochs_range, val_loss, label=\"Validation Loss\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.title(\"Training and Validation Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(sample_test_images,  sample_test_labels, verbose=2)\n",
    "\n",
    "print('\\nTest loss:', test_loss)\n",
    "print('\\nTest accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make predictions using the trained model. Here it's only done on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(sample_test_images)\n",
    "\n",
    "# decode one-hot encoded labels\n",
    "predictions = tf.argmax(predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Predictions:\", predictions)\n",
    "print(\"Labels:\", sample_test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "n_misclassified = 0\n",
    "\n",
    "for i in range(64):\n",
    "    prediction = class_names[predictions[i]]\n",
    "    label = class_names[sample_test_labels[i]]\n",
    "\n",
    "    if prediction != label:\n",
    "        n_misclassified +=1\n",
    "        plt.subplot(5,5,n_misclassified)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.grid(False)\n",
    "        plt.imshow(sample_test_images[i], cmap=plt.cm.binary)\n",
    "        plt.xlabel(\"prediction: %s \\n label: %s\" % (prediction, label))\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ANN",
   "language": "python",
   "name": "ann"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
