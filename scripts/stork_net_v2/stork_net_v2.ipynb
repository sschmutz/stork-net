{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stork net v2 - multiclass classification of stork nest images\n",
    "*Module ANN & DL  \n",
    "May 2020  \n",
    "Ueli Mauch & Stefan Schmutz*\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/sschmutz/stork-net/blob/master/scripts/stork_net_v2/stork_net_v2.ipynb)  \n",
    "\n",
    "The aim of Stork net is to classify images of a stork nest. The model should be able to predict how many storks are present. Images were collected from a publicly available [webcam](https://www.berner-storch.ch/webcam/) and manually labeled.  \n",
    "For simple access and version control of the labeled images, a GitHub repository [stork-net-dataset](https://github.com/sschmutz/stork-net-dataset) is provided.\n",
    "\n",
    "This version of Stork net (v2) can classify up to 3 storks (4 classes). It achieves this by training a relatively simple convolutional neural network (CNN).  \n",
    "The implementation of a more complex network by transfer learning from e.g. [MobileNet V2](https://arxiv.org/pdf/1801.04381.pdf) will be set aside for a later version of Stork net."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the following necessary libraries\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import os\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading images\n",
    "Labeled images are already split and available on GitHub ([stork-net-dataset](https://github.com/sschmutz/stork-net-dataset)).\n",
    "The full dataset will be downloaded with the following command, this enables us to use this notebook in google colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the complete labeled dataset will be downloaded to ~/.keras/datasets/\n",
    "data_dir = tf.keras.utils.get_file(origin=\"https://github.com/sschmutz/stork-net-dataset/archive/master.zip\", fname=\"stork-net-dataset-master.zip\", extract=True)\n",
    "# remove the .zip file extension since the data is already extracted\n",
    "data_dir = pathlib.Path(os.path.splitext(data_dir)[0])\n",
    "\n",
    "# the training split has been furher separated into a \"train\" and \"validation\" part\n",
    "train_dir = pathlib.Path(data_dir, \"2019_train\", \"train\")\n",
    "validation_dir = pathlib.Path(data_dir, \"2019_train\", \"validation\")\n",
    "\n",
    "test_dir = pathlib.Path(data_dir, \"2019_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the statistics on how many images there are in each split\n",
    "total_train = len(list(train_dir.glob(\"*/*.jpg\")))\n",
    "total_val = len(list(validation_dir.glob(\"*/*.jpg\")))\n",
    "total_test = len(list(test_dir.glob(\"*/*.jpg\")))\n",
    "\n",
    "# the class names are also saved, note that the order is important since the model output will have the same\n",
    "class_names = np.array([item.name for item in train_dir.glob(\"*\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The images will be loaded in batches of size defined as the variable `batch_size`.\n",
    "\n",
    "Data augmentation could be defined inside ***ImageDataGenerator()***, see the respective section on the [keras website](https://keras.io/api/preprocessing/image/).  \n",
    "We've tried data augmentation (if applied, only do it on the training data) as described in [this tutorial](https://www.tensorflow.org/tutorials/images/classification). It didn't improve the model so we did not include it in this version of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the images from uint8 to float32 in range [0,1]\n",
    "train_image_generator = ImageDataGenerator(rescale=1./255)\n",
    "validation_image_generator = ImageDataGenerator(rescale=1./255)\n",
    "test_image_generator = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64 \n",
    "epochs = 15\n",
    "img_height = 480\n",
    "img_width = 640\n",
    "channels = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_gen = train_image_generator.flow_from_directory(batch_size=batch_size,\n",
    "                                                           directory=train_dir,\n",
    "                                                           shuffle=True,\n",
    "                                                           target_size=(img_height, img_width),\n",
    "                                                           class_mode=\"categorical\",\n",
    "                                                           classes = list(class_names))\n",
    "\n",
    "val_data_gen = validation_image_generator.flow_from_directory(batch_size=batch_size,\n",
    "                                                              directory=validation_dir,\n",
    "                                                              shuffle=True,\n",
    "                                                              target_size=(img_height, img_width),\n",
    "                                                              class_mode=\"categorical\",\n",
    "                                                              classes = list(class_names))\n",
    "\n",
    "test_data_gen = test_image_generator.flow_from_directory(batch_size=batch_size,\n",
    "                                                         directory=test_dir,\n",
    "                                                         shuffle=True,\n",
    "                                                         target_size=(img_height, img_width),\n",
    "                                                         class_mode=\"categorical\",\n",
    "                                                         classes = list(class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get images and respective labels (one-hot encoded)\n",
    "training_images, training_labels = next(train_data_gen)\n",
    "validation_images, validation_labels = next(val_data_gen)\n",
    "test_images, test_labels = next(test_data_gen)\n",
    "\n",
    "# decode one-hot encoded labels\n",
    "training_labels_decoded = tf.argmax(training_labels, axis=1)\n",
    "validation_labels_decoded = tf.argmax(validation_labels, axis=1)\n",
    "test_labels_decoded = tf.argmax(test_labels, axis=1)\n",
    "\n",
    "# example of 25 images with their labels\n",
    "plt.figure(figsize=(10,10))\n",
    "for i in range(25):\n",
    "    plt.subplot(5,5,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(training_images[i], cmap=plt.cm.binary)\n",
    "    plt.xlabel(class_names[training_labels_decoded[i]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 2'940 labeled images in total which were split as follows:\n",
    "- 2'057 training (70%)\n",
    "- 442 validation (15%)\n",
    "- 441 testing (15%)\n",
    "\n",
    "If we look at the distribution of the classes, we see that images with 3 storks are underrepresented. It happened because the images were sampled randomly. This class imbalance could lead to a biased model, but let's see.\n",
    "\n",
    "<img src=\"figures/class_imbalance.png\" alt=\"class_imbalance\" style=\"width: 500px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creation and training a CNN model\n",
    "The relatively simple model consists of 3 convolutional layers including max pooling and is followed by 2 fully connected layers. There are 4 output nodes which represent, due to the softmax activation, probabilities of belonging to the respective classes.\n",
    "\n",
    "<img src=\"figures/CNN_model.png\" alt=\"CNN_model\" style=\"height: 500px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(16, 3, padding=\"same\", activation=\"relu\", input_shape=(img_height, img_width, channels)),\n",
    "    MaxPooling2D(),\n",
    "    Dropout(0.1),\n",
    "    Conv2D(32, 3, padding=\"same\", activation=\"relu\"),\n",
    "    MaxPooling2D(),\n",
    "    Conv2D(64, 3, padding=\"same\", activation=\"relu\"),\n",
    "    MaxPooling2D(),\n",
    "    Dropout(0.1),\n",
    "    Flatten(),\n",
    "    Dense(64, activation=\"relu\"),\n",
    "    Dense(4, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The popular optimizer [ADAM](https://arxiv.org/pdf/1412.6980.pdf) has been proven to work well for this problem. Categorical Cross-Entropy loss will be computed since it's a task of multiclass classification where we'd like to have probabilities to all classes as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\",\n",
    "              loss=\"categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# execute the training\n",
    "history = model.fit(\n",
    "    train_data_gen,\n",
    "    steps_per_epoch=total_train // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=val_data_gen,\n",
    "    validation_steps=total_val // batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the trained model\n",
    "model.save(\"stork_net_v2.h5\")\n",
    "\n",
    "# this saved model can be loaded using the following command\n",
    "# model = tf.keras.models.load_model(\"stork_net_v2.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "To track accuracy and loss of both, training and validation set, those numbers are plotted. It's important to confirm that the model is neither under- nor overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history[\"accuracy\"]\n",
    "val_acc = history.history[\"val_accuracy\"]\n",
    "\n",
    "loss=history.history[\"loss\"]\n",
    "val_loss=history.history[\"val_loss\"]\n",
    "\n",
    "epochs_range = range(epochs)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label=\"Training Accuracy\")\n",
    "plt.plot(epochs_range, val_acc, label=\"Validation Accuracy\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.title(\"Training and Validation Accuracy\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label=\"Training Loss\")\n",
    "plt.plot(epochs_range, val_loss, label=\"Validation Loss\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.title(\"Training and Validation Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally to evaluate the model, accuracy and loss of predictions of the test set can be computed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=0)\n",
    "\n",
    "print('\\nTest loss:', test_loss)\n",
    "print('\\nTest accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we look at the misclassified images over all labeled images we see that the difference between Reference (label) and Prediction is at maximum 1.  \n",
    "The numbers in the tiles in the following figure represent the amount of images, while the color shows the percentage of misclassified images per labeled class.  \n",
    "This clearly shows that our model has more trouble classifying 3 storks compared to the other classes. As suspected, the class imbalance of the labeled images could possibly be the cause.\n",
    "\n",
    "<img src=\"figures/misclassification.png\" alt=\"misclassification\" style=\"width: 500px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction\n",
    "This section demonstrates how to make predictions using the trained model. Here it's applied on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(test_images)\n",
    "\n",
    "# decode one-hot encoded labels\n",
    "predictions_decoded = tf.argmax(predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot all misclassified image of a test image batch\n",
    "plt.figure(figsize=(20,20))\n",
    "n_misclassified = 0\n",
    "\n",
    "for i in range(64):\n",
    "    prediction = class_names[predictions_decoded[i]]\n",
    "    label = class_names[test_labels_decoded[i]]\n",
    "\n",
    "    if prediction != label:\n",
    "        n_misclassified +=1\n",
    "        plt.subplot(5,5,n_misclassified)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.grid(False)\n",
    "        plt.imshow(test_images[i], cmap=plt.cm.binary)\n",
    "        plt.xlabel(\"prediction: %s \\n label: %s\" % (prediction, label))\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Despite using a simple CNN, the task of classifying the number of storks present can be done relatively well. The trend of accuracy and loss over the epochs do not show a strong sign of overfitting.  \n",
    "The performance however with an accuracy of around 90% could (and probably should) be further improved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outlook\n",
    "In future steps, the issue of underrepresented class 3 (and no classes for larger amounts of storks) should be tackled. Labeling additional images of those classes would be a next task.  \n",
    "To additionaly improve the performance, transfer learning from a more sophisticated network (e.g. [MobileNet V2](https://arxiv.org/pdf/1801.04381.pdf)) could be applied. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
